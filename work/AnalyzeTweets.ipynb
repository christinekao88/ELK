{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install twint, optimus and reqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting optimuspyspark\n",
      "  Using cached optimuspyspark-2.2.29-py3-none-any.whl (39.1 MB)\n",
      "Collecting aiohttp\n",
      "  Using cached aiohttp-3.6.2-cp37-cp37m-manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting aiodns\n",
      "  Using cached aiodns-2.0.0-py2.py3-none-any.whl (4.8 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.9.1-py3-none-any.whl (115 kB)\n",
      "Collecting cchardet\n",
      "  Using cached cchardet-2.1.6-cp37-cp37m-manylinux2010_x86_64.whl (242 kB)\n",
      "Collecting elasticsearch\n",
      "  Using cached elasticsearch-7.8.0-py2.py3-none-any.whl (188 kB)\n",
      "Requirement already satisfied: pysocks in /opt/conda/lib/python3.7/site-packages (from -r requirements.txt (line 7)) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23.0 in /home/jovyan/.local/lib/python3.7/site-packages (from -r requirements.txt (line 8)) (1.0.5)\n",
      "Collecting aiohttp_socks\n",
      "  Using cached aiohttp_socks-0.3.9-py3-none-any.whl (17 kB)\n",
      "Collecting schedule\n",
      "  Using cached schedule-0.6.0-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting geopy\n",
      "  Using cached geopy-2.0.0-py3-none-any.whl (111 kB)\n",
      "Collecting nest_asyncio\n",
      "  Using cached nest_asyncio-1.3.3-py3-none-any.whl (4.7 kB)\n",
      "Collecting TextBlob\n",
      "  Using cached textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Collecting wordcloud\n",
      "  Using cached wordcloud-1.7.0-cp37-cp37m-manylinux1_x86_64.whl (364 kB)\n",
      "Collecting deepdiff==4.0.6\n",
      "  Using cached deepdiff-4.0.6-py3-none-any.whl (47 kB)\n",
      "Requirement already satisfied: flask==1.0.2 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.0.2)\n",
      "Collecting fastnumbers==2.2.1\n",
      "  Using cached fastnumbers-2.2.1-cp37-cp37m-manylinux1_x86_64.whl (55 kB)\n",
      "Requirement already satisfied: keras==2.2.4 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.2.4)\n",
      "Requirement already satisfied: tensorflow==1.13.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: kombu==4.6.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (4.6.1)\n",
      "Requirement already satisfied: setuptools==41.6.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (41.6.0)\n",
      "Requirement already satisfied: findspark==1.3.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting psutil==5.6.3\n",
      "  Using cached psutil-5.6.3.tar.gz (435 kB)\n",
      "Requirement already satisfied: h2o-pysparkling-2.4==2.4.13 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.4.13)\n",
      "Processing /home/jovyan/.cache/pip/wheels/7b/6e/09/d25c862eee75180ba60ca16677ea326a68f4399814623d909a/imgkit-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: backoff==1.8.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.8.0)\n",
      "Requirement already satisfied: Jinja2==2.10.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.10.1)\n",
      "Collecting packaging==19.1\n",
      "  Using cached packaging-19.1-py2.py3-none-any.whl (30 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/26/c4/11/47182172c00397e48f132d521b6035ebf6a48842f7063f5292/PyPika-0.32.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: simplejson==3.16.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (3.16.0)\n",
      "Requirement already satisfied: requests==2.20.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.20.0)\n",
      "Collecting ipython==7.5.0\n",
      "  Using cached ipython-7.5.0-py3-none-any.whl (770 kB)\n",
      "Collecting multipledispatch==0.6.0\n",
      "  Using cached multipledispatch-0.6.0-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: matplotlib==3.0.3 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (3.0.3)\n",
      "Requirement already satisfied: glom==19.10.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (19.10.0)\n",
      "Requirement already satisfied: numpy==1.17.2 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.17.2)\n",
      "Requirement already satisfied: pyspark==2.4.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.4.1)\n",
      "Requirement already satisfied: seaborn==0.9.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (0.9.0)\n",
      "Collecting deprecated==1.2.5\n",
      "  Using cached Deprecated-1.2.5-py2.py3-none-any.whl (8.1 kB)\n",
      "Requirement already satisfied: singleton-decorator==1.0.0 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (1.0.0)\n",
      "Requirement already satisfied: statsmodels==0.10.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (0.10.1)\n",
      "Collecting pymongo==3.9.0\n",
      "  Using cached pymongo-3.9.0-cp37-cp37m-manylinux1_x86_64.whl (447 kB)\n",
      "Requirement already satisfied: ordered-set==3.1.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (3.1.1)\n",
      "Processing /home/jovyan/.cache/pip/wheels/74/bc/ac/8904cf8a9ad4d508f2e3e02ac7c7560d4ea0ecd29e5b62571e/humanize-0.5.1-py3-none-any.whl\n",
      "Collecting pyarrow==0.13.0\n",
      "  Using cached pyarrow-0.13.0-cp37-cp37m-manylinux1_x86_64.whl (48.5 MB)\n",
      "Requirement already satisfied: ratelimit==2.2.1 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: pygments>=2.2.0 in /opt/conda/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.6.1)\n",
      "Requirement already satisfied: cryptography==2.7 in /home/jovyan/.local/lib/python3.7/site-packages (from optimuspyspark->-r requirements.txt (line 1)) (2.7)\n",
      "Collecting tqdm==4.28.1\n",
      "  Using cached tqdm-4.28.1-py2.py3-none-any.whl (45 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->-r requirements.txt (line 2)) (19.3.0)\n",
      "Collecting async-timeout<4.0,>=3.0\n",
      "  Using cached async_timeout-3.0.1-py3-none-any.whl (8.2 kB)\n",
      "Collecting multidict<5.0,>=4.5\n",
      "  Using cached multidict-4.7.6-cp37-cp37m-manylinux1_x86_64.whl (149 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Using cached yarl-1.4.2-cp37-cp37m-manylinux1_x86_64.whl (256 kB)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->-r requirements.txt (line 2)) (3.0.4)\n",
      "Collecting pycares>=3.0.0\n",
      "  Using cached pycares-3.1.1-cp37-cp37m-manylinux2010_x86_64.whl (228 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Using cached soupsieve-2.0.1-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from elasticsearch->-r requirements.txt (line 6)) (2020.4.5.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from elasticsearch->-r requirements.txt (line 6)) (1.25.9)\n",
      "Requirement already satisfied: pytz>=2017.2 in /home/jovyan/.local/lib/python3.7/site-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2020.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.23.0->-r requirements.txt (line 8)) (2.8.1)\n",
      "Collecting geographiclib<2,>=1.49\n",
      "  Using cached geographiclib-1.50-py3-none-any.whl (38 kB)\n",
      "Processing /home/jovyan/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266/nltk-3.5-py3-none-any.whl\n",
      "Collecting pillow\n",
      "  Using cached Pillow-7.2.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Collecting jsonpickle>=1.0\n",
      "  Using cached jsonpickle-1.4.1-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: click>=5.1 in /home/jovyan/.local/lib/python3.7/site-packages (from flask==1.0.2->optimuspyspark->-r requirements.txt (line 1)) (7.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in /home/jovyan/.local/lib/python3.7/site-packages (from flask==1.0.2->optimuspyspark->-r requirements.txt (line 1)) (1.0.1)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/jovyan/.local/lib/python3.7/site-packages (from flask==1.0.2->optimuspyspark->-r requirements.txt (line 1)) (1.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-applications>=1.0.6 in /home/jovyan/.local/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (1.0.8)\n",
      "Requirement already satisfied: h5py in /home/jovyan/.local/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (2.10.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (1.15.0)\n",
      "Requirement already satisfied: pyyaml in /home/jovyan/.local/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (5.3.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /home/jovyan/.local/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (1.1.2)\n",
      "Requirement already satisfied: scipy>=0.14 in /home/jovyan/.local/lib/python3.7/site-packages (from keras==2.2.4->optimuspyspark->-r requirements.txt (line 1)) (1.5.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (0.34.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (3.12.2)\n",
      "Requirement already satisfied: tensorboard<1.14.0,>=1.13.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (1.30.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (0.3.3)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (0.9.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (0.8.1)\n",
      "Requirement already satisfied: tensorflow-estimator<1.14.0rc0,>=1.13.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (1.13.0)\n",
      "Requirement already satisfied: amqp<3.0,>=2.5.0 in /home/jovyan/.local/lib/python3.7/site-packages (from kombu==4.6.1->optimuspyspark->-r requirements.txt (line 1)) (2.6.0)\n",
      "Requirement already satisfied: tabulate in /home/jovyan/.local/lib/python3.7/site-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark->-r requirements.txt (line 1)) (0.8.7)\n",
      "Requirement already satisfied: colorama>=0.3.8 in /home/jovyan/.local/lib/python3.7/site-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark->-r requirements.txt (line 1)) (0.4.3)\n",
      "Requirement already satisfied: future in /home/jovyan/.local/lib/python3.7/site-packages (from h2o-pysparkling-2.4==2.4.13->optimuspyspark->-r requirements.txt (line 1)) (0.18.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from Jinja2==2.10.1->optimuspyspark->-r requirements.txt (line 1)) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging==19.1->optimuspyspark->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/jovyan/.local/lib/python3.7/site-packages (from requests==2.20.0->optimuspyspark->-r requirements.txt (line 1)) (2.7)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.7.5)\n",
      "Collecting prompt-toolkit<2.1.0,>=2.0.0\n",
      "  Using cached prompt_toolkit-2.0.10-py3-none-any.whl (340 kB)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (4.8.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (4.3.3)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (4.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.7/site-packages (from ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.17.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/jovyan/.local/lib/python3.7/site-packages (from matplotlib==3.0.3->optimuspyspark->-r requirements.txt (line 1)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/jovyan/.local/lib/python3.7/site-packages (from matplotlib==3.0.3->optimuspyspark->-r requirements.txt (line 1)) (0.10.0)\n",
      "Requirement already satisfied: face in /home/jovyan/.local/lib/python3.7/site-packages (from glom==19.10.0->optimuspyspark->-r requirements.txt (line 1)) (20.1.1)\n",
      "Requirement already satisfied: boltons>=19.3.0 in /home/jovyan/.local/lib/python3.7/site-packages (from glom==19.10.0->optimuspyspark->-r requirements.txt (line 1)) (20.2.0)\n",
      "Requirement already satisfied: py4j==0.10.7 in /home/jovyan/.local/lib/python3.7/site-packages (from pyspark==2.4.1->optimuspyspark->-r requirements.txt (line 1)) (0.10.7)\n",
      "Processing /home/jovyan/.cache/pip/wheels/62/76/4c/aa25851149f3f6d9785f6c869387ad82b3fd37582fa8147ac6/wrapt-1.12.1-py3-none-any.whl\n",
      "Requirement already satisfied: patsy>=0.4.0 in /home/jovyan/.local/lib/python3.7/site-packages (from statsmodels==0.10.1->optimuspyspark->-r requirements.txt (line 1)) (0.5.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /opt/conda/lib/python3.7/site-packages (from cryptography==2.7->optimuspyspark->-r requirements.txt (line 1)) (1.14.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /home/jovyan/.local/lib/python3.7/site-packages (from cryptography==2.7->optimuspyspark->-r requirements.txt (line 1)) (1.3.0)\n",
      "Collecting joblib\n",
      "  Using cached joblib-0.16.0-py3-none-any.whl (300 kB)\n",
      "Collecting regex\n",
      "  Using cached regex-2020.6.8-cp37-cp37m-manylinux2010_x86_64.whl (661 kB)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from jsonpickle>=1.0->deepdiff==4.0.6->optimuspyspark->-r requirements.txt (line 1)) (1.6.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (3.2.2)\n",
      "Requirement already satisfied: mock>=2.0.0 in /home/jovyan/.local/lib/python3.7/site-packages (from tensorflow-estimator<1.14.0rc0,>=1.13.0->tensorflow==1.13.1->optimuspyspark->-r requirements.txt (line 1)) (4.0.2)\n",
      "Requirement already satisfied: vine<5.0.0a1,>=1.1.3 in /home/jovyan/.local/lib/python3.7/site-packages (from amqp<3.0,>=2.5.0->kombu==4.6.1->optimuspyspark->-r requirements.txt (line 1)) (1.3.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.2.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.6.0)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.7/site-packages (from traitlets>=4.2->ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.2.0)\n",
      "Requirement already satisfied: parso>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.10->ipython==7.5.0->optimuspyspark->-r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi!=1.11.3,>=1.8->cryptography==2.7->optimuspyspark->-r requirements.txt (line 1)) (2.20)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->jsonpickle>=1.0->deepdiff==4.0.6->optimuspyspark->-r requirements.txt (line 1)) (3.1.0)\n",
      "Building wheels for collected packages: psutil\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for psutil (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-d9zmqllm\n",
      "       cwd: /tmp/pip-install-5dxco19i/psutil/\n",
      "  Complete output (41 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.7\n",
      "  creating build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_compat.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_common.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/__init__.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_psosx.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_pswindows.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_pslinux.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_psposix.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_psaix.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_psbsd.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  copying psutil/_pssunos.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "  creating build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_unicode.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_posix.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_sunos.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_osx.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_windows.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_system.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_memory_leaks.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_linux.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_misc.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_aix.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_connections.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/__init__.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_bsd.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_contracts.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/runner.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/test_process.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  copying psutil/tests/__main__.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "  running build_ext\n",
      "  building 'psutil._psutil_linux' extension\n",
      "  creating build/temp.linux-x86_64-3.7\n",
      "  creating build/temp.linux-x86_64-3.7/psutil\n",
      "  gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_VERSION=563 -DPSUTIL_LINUX=1 -DPSUTIL_ETHTOOL_MISSING_TYPES=1 -I/opt/conda/include/python3.7m -c psutil/_psutil_common.c -o build/temp.linux-x86_64-3.7/psutil/_psutil_common.o\n",
      "  unable to execute 'gcc': No such file or directory\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for psutil\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for psutil\n",
      "Failed to build psutil\n",
      "\u001b[31mERROR: optimuspyspark 2.2.29 has requirement pandas==0.24.2, but you'll have pandas 1.0.5 which is incompatible.\u001b[0m\n",
      "Installing collected packages: jsonpickle, deepdiff, fastnumbers, psutil, imgkit, packaging, pypika, prompt-toolkit, ipython, multipledispatch, wrapt, deprecated, pymongo, humanize, pyarrow, tqdm, optimuspyspark, async-timeout, multidict, yarl, aiohttp, pycares, aiodns, soupsieve, beautifulsoup4, cchardet, elasticsearch, aiohttp-socks, schedule, geographiclib, geopy, nest-asyncio, joblib, regex, nltk, TextBlob, pillow, wordcloud\n",
      "    Running setup.py install for psutil ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-0eygweeo/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/jovyan/.local/include/python3.7m/psutil\n",
      "         cwd: /tmp/pip-install-5dxco19i/psutil/\n",
      "    Complete output (41 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.7\n",
      "    creating build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_compat.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_common.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/__init__.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_psosx.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_pswindows.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_pslinux.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_psposix.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_psaix.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_psbsd.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    copying psutil/_pssunos.py -> build/lib.linux-x86_64-3.7/psutil\n",
      "    creating build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_unicode.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_posix.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_sunos.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_osx.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_windows.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_system.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_memory_leaks.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_linux.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_misc.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_aix.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_connections.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/__init__.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_bsd.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_contracts.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/runner.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/test_process.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    copying psutil/tests/__main__.py -> build/lib.linux-x86_64-3.7/psutil/tests\n",
      "    running build_ext\n",
      "    building 'psutil._psutil_linux' extension\n",
      "    creating build/temp.linux-x86_64-3.7\n",
      "    creating build/temp.linux-x86_64-3.7/psutil\n",
      "    gcc -pthread -B /opt/conda/compiler_compat -Wl,--sysroot=/ -Wsign-compare -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -fPIC -DPSUTIL_POSIX=1 -DPSUTIL_VERSION=563 -DPSUTIL_LINUX=1 -DPSUTIL_ETHTOOL_MISSING_TYPES=1 -I/opt/conda/include/python3.7m -c psutil/_psutil_common.c -o build/temp.linux-x86_64-3.7/psutil/_psutil_common.o\n",
      "    unable to execute 'gcc': No such file or directory\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /opt/conda/bin/python3.7 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-5dxco19i/psutil/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-0eygweeo/install-record.txt --single-version-externally-managed --user --prefix= --compile --install-headers /home/jovyan/.local/include/python3.7m/psutil Check the logs for full command output.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install --user -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting twint\r\n",
      "  Cloning https://github.com/twintproject/twint.git (to revision origin/master) to /tmp/pip-install-9cfiemi9/twint\r\n",
      "  Running command git clone -q https://github.com/twintproject/twint.git /tmp/pip-install-9cfiemi9/twint\r\n",
      "\u001b[31m  ERROR: Error [Errno 2] No such file or directory: 'git': 'git' while executing command git clone -q https://github.com/twintproject/twint.git /tmp/pip-install-9cfiemi9/twint\u001b[0m\r\n",
      "\u001b[31mERROR: Cannot find command 'git' - do you have 'git' installed and in your PATH?\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat 'src/twint': No such file or directory\n",
      "rm: cannot remove 'src': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mv src/twint .\n",
    "!rm -r src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"twint/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'twint'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-5772b804c290>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtwint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'twint'"
     ]
    }
   ],
   "source": [
    "import twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimus import Optimus\n",
    "op = Optimus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up TWINT config\n",
    "c = twint.Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve compatibility issues with notebooks and RunTime errors.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search for data science tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.Search = \"data science\"\n",
    "# Custom output format\n",
    "c.Format = \"Username: {username} |  Tweet: {tweet}\"\n",
    "c.Limit = 1\n",
    "c.Pandas = True\n",
    "\n",
    "twint.run.Search(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving results into Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def available_columns():\n",
    "    return twint.output.panda.Tweets_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twint_to_pandas(columns):\n",
    "    return twint.output.panda.Tweets_df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_columns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd = twint_to_pandas([\"date\", \"username\", \"tweet\", \"hashtags\", \"nlikes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data to Optimus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = op.create.data_frame(pdf= df_pd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets = df.cols.remove_accents(\"tweet\") \\\n",
    "                 .cols.remove_special_chars(\"tweet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = clean_tweets.select(\"tweet\").rdd.flatMap(lambda x: x).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze sentiment of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printmd(string, color=None):\n",
    "    colorstr = \"<span style='color:{}'>{}</span>\".format(color, string)\n",
    "    display(Markdown(colorstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweets:\n",
    "    print(tweet)\n",
    "    analysis = TextBlob(tweet)\n",
    "    print(analysis.sentiment)\n",
    "    if analysis.sentiment[0]>0:\n",
    "        printmd('Positive', color=\"green\")\n",
    "    elif analysis.sentiment[0]<0:\n",
    "        printmd('Negative', color=\"red\")\n",
    "    else:\n",
    "        printmd(\"Neutral\", color=\"grey\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add sentiments to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blob(sentence):\n",
    "    temp = TextBlob(sentence).sentiment[0]\n",
    "    if temp == 0.0:\n",
    "        return 0.0 # Neutral\n",
    "    elif temp >= 0.0:\n",
    "        return 1.0 # Positive\n",
    "    else:\n",
    "        return 2.0 # Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = udf(apply_blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweets.withColumn(\"sentiment\", sentiment(clean_tweets['tweet'])).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Â Making the code modular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import twint\n",
    "import sys\n",
    "sys.path.append(\"twint/\")\n",
    "\n",
    "# Set up TWINT config\n",
    "import twint\n",
    "c = twint.Config()\n",
    "\n",
    "# Other imports\n",
    "import seaborn as sns\n",
    "import os\n",
    "from optimus import Optimus\n",
    "op = Optimus()\n",
    "\n",
    "# Solve compatibility issues with notebooks and RunTime errors.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Disable annoying printing\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The code with the magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "# Function to get sentiment \n",
    "def apply_blob(sentence):\n",
    "    temp = TextBlob(sentence).sentiment[0]\n",
    "    if temp == 0.0:\n",
    "        return 0.0 # Neutral\n",
    "    elif temp >= 0.0:\n",
    "        return 1.0 # Positive\n",
    "    else:\n",
    "        return 2.0 # Negative\n",
    "\n",
    "# UDF to write sentiment on DF\n",
    "sentiment = udf(apply_blob, DoubleType())\n",
    "\n",
    "# Transform result to pandas\n",
    "def twint_to_pandas(columns):\n",
    "    return twint.output.panda.Tweets_df[columns]\n",
    "\n",
    "def tweets_sentiment(search, limit=1):\n",
    "    c.Search = search\n",
    "    # Custom output format\n",
    "    c.Format = \"Username: {username} |  Tweet: {tweet}\"\n",
    "    c.Limit = limit\n",
    "    c.Pandas = True\n",
    "    with HiddenPrints():\n",
    "        print(twint.run.Search(c))\n",
    "    \n",
    "    # Transform tweets to pandas DF\n",
    "    df_pd = twint_to_pandas([\"date\", \"username\", \"tweet\", \"hashtags\", \"nlikes\"])\n",
    "    \n",
    "    # Transform Pandas DF to Optimus/Spark DF\n",
    "    df = op.create.data_frame(pdf= df_pd)\n",
    "    \n",
    "    # Clean tweets\n",
    "    clean_tweets = df.cols.remove_accents(\"tweet\") \\\n",
    "                 .cols.remove_special_chars(\"tweet\")\n",
    "    \n",
    "    # Add sentiment to final DF\n",
    "    return clean_tweets.withColumn(\"sentiment\", sentiment(clean_tweets['tweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = tweets_sentiment(\"data science\", limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see the distribution of the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res_pandas = df_result.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_res_pandas['sentiment'])\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets do more with Twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys, os\n",
    "sys.path.append(\"twint/\")\n",
    "\n",
    "import twint\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import path\n",
    "\n",
    "# Solve compatibility issues with notebooks and RunTime errors.\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable annoying printing\n",
    "\n",
    "class HiddenPrints:\n",
    "    def __enter__(self):\n",
    "        self._original_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        sys.stdout.close()\n",
    "        sys.stdout = self._original_stdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tweets easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(search, limit=100):\n",
    "    c = twint.Config()\n",
    "    c.Search = search\n",
    "    c.Limit = limit\n",
    "    c.Pandas = True\n",
    "    c.Pandas_clean = True\n",
    "\n",
    "    with HiddenPrints():\n",
    "        print(twint.run.Search(c))\n",
    "    return twint.output.panda.Tweets_df[[\"username\",\"tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets(\"data science\", limit=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate word cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "text = tweets.tweet.values\n",
    "\n",
    "# adding movie script specific stopwords\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.add(\"https\")\n",
    "stopwords.add(\"xa0\")\n",
    "stopwords.add(\"xa0'\")\n",
    "stopwords.add(\"bitly\")\n",
    "stopwords.add(\"bit\")\n",
    "stopwords.add(\"ly\")\n",
    "stopwords.add(\"twitter\")\n",
    "stopwords.add(\"pic\")\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    background_color = 'black',\n",
    "    width = 1000,\n",
    "    height = 500,\n",
    "    stopwords = stopwords).generate(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_word_cloud(tweets):\n",
    "    \n",
    "    # Getting the text out of the tweets\n",
    "    text = tweets.tweet.values\n",
    "    \n",
    "    # adding movie script specific stopwords\n",
    "    stopwords = set(STOPWORDS)\n",
    "    stopwords.add(\"https\")\n",
    "    stopwords.add(\"xa0\")\n",
    "    stopwords.add(\"xa0'\")\n",
    "    stopwords.add(\"bitly\")\n",
    "    stopwords.add(\"bit\")\n",
    "    stopwords.add(\"ly\")\n",
    "    stopwords.add(\"twitter\")\n",
    "    stopwords.add(\"pic\")\n",
    "\n",
    "    wordcloud = WordCloud(\n",
    "        background_color = 'black',\n",
    "        width = 1000,\n",
    "        height = 500,\n",
    "        stopwords = stopwords).generate(str(text))\n",
    "    \n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.rcParams['figure.figsize'] = [10, 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = get_tweets(\"artificial intelligence\", limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_word_cloud(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = tweets_sentiment(\"data science\", limit=10000)\n",
    "df_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
